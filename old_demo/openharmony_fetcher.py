#!/usr/bin/env python3
"""
OpenHarmonyFetcher - ç”¨äºè·å–OpenHarmonyä»“åº“æ•°æ®çš„è·å–å™¨
æ”¯æŒå¤šç§fetcherç±»å‹ï¼šWebpageFetcher, APIFetcher, APIBatchFetcher
å¯¹åº” openharmony.yaml ä¸­çš„æ•°æ®æºï¼ˆæ”¯æŒ OHPM å’Œ GitCodeï¼‰
"""

import os
import json
import requests
from typing import Optional, Dict, Any, List
import time
from bs4 import BeautifulSoup


class BaseFetcher:
    """åŸºç¡€è·å–å™¨ç±»"""
    
    def __init__(self, url: str, fetch_timeout: int = 60):
        self.url = url
        self.fetch_timeout = fetch_timeout
        self.session = requests.Session()
        
        # è®¾ç½®è¯·æ±‚å¤´
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Accept': 'application/json,text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8'
        })

        # å¦‚æœæä¾›äº† GitCode ä»¤ç‰Œï¼Œåˆ™è‡ªåŠ¨é™„åŠ åˆ°è¯·æ±‚å¤´ï¼ˆå…¼å®¹ä¸¤ç§æ–¹å¼ï¼‰
        try:
            import os as _os
            _token = _os.getenv('GITCODE_TOKEN') or _os.getenv('GITCODE_PRIVATE_TOKEN')
            if _token:
                # åŒæ—¶è®¾ç½®ä¸¤ç§å¸¸è§å¤´éƒ¨ï¼Œåç«¯ä¼šæ‹©ä¸€è¯†åˆ«
                self.session.headers['Authorization'] = f'Bearer {_token}'
                self.session.headers['PRIVATE-TOKEN'] = _token
        except Exception:
            # ç¯å¢ƒå˜é‡ä¸å¯ç”¨æ—¶å¿½ç•¥
            pass
    
    def fetch(self, output_path: str) -> bool:
        """è·å–æ•°æ®å¹¶ä¿å­˜åˆ°æŒ‡å®šè·¯å¾„"""
        raise NotImplementedError("Subclasses must implement fetch()")


class WebpageFetcher(BaseFetcher):
    """
    ç½‘é¡µæŠ“å–å™¨ - ç”¨äºæŠ“å–ç½‘é¡µå†…å®¹ï¼ˆHTMLã€JSONç­‰ï¼‰
    å¯¹åº” yaml ä¸­çš„ WebpageFetcher
    """
    
    def fetch(self, output_path: str) -> bool:
        """æŠ“å–ç½‘é¡µå†…å®¹å¹¶ä¿å­˜"""
        try:
            print(f"[WebpageFetcher] æ­£åœ¨æŠ“å–é¡µé¢: {self.url}")
            
            response = self.session.get(self.url, timeout=self.fetch_timeout)
            response.raise_for_status()
            
            # ä¿å­˜HTMLå†…å®¹
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(response.text)
            
            file_size = os.path.getsize(output_path)
            print(f"[WebpageFetcher] é¡µé¢æŠ“å–æˆåŠŸï¼Œå¤§å°: {file_size} å­—èŠ‚")
            
            return True
            
        except Exception as e:
            print(f"[WebpageFetcher] æŠ“å–å¤±è´¥: {e}")
            return False


class APIFetcher(BaseFetcher):
    """
    APIæŠ“å–å™¨ - ç”¨äºæŠ“å– OHPM API æ•°æ®ï¼Œæ”¯æŒåˆ†é¡µ
    å¯¹åº” yaml ä¸­çš„ ohpm_api source
    URLç¤ºä¾‹: https://ohpm.openharmony.cn/api/v1/packages/search?keyword=js&page=1&pageSize=100
    """
    
    def fetch(self, output_path: str) -> bool:
        """æŠ“å–APIæ•°æ®å¹¶ä¿å­˜ä¸ºJSON"""
        try:
            print(f"[APIFetcher] æ­£åœ¨æŠ“å–API: {self.url}")
            
            all_packages = []
            page = 1
            max_pages = 100  # æœ€å¤§é¡µæ•°é™åˆ¶
            
            while page <= max_pages:
                # æ„å»ºåˆ†é¡µURL
                page_url = self._build_page_url(page)
                print(f"[APIFetcher] æ­£åœ¨è·å–ç¬¬ {page} é¡µ...")
                
                response = self.session.get(page_url, timeout=self.fetch_timeout)
                response.raise_for_status()
                
                data = response.json()
                
                # è§£æå“åº”æ ¼å¼
                packages = self._extract_packages(data)
                
                if not packages:
                    print(f"[APIFetcher] ç¬¬ {page} é¡µæ— æ•°æ®ï¼Œåœæ­¢æŠ“å–")
                    break
                
                all_packages.extend(packages)
                print(f"[APIFetcher] ç¬¬ {page} é¡µè·å–åˆ° {len(packages)} ä¸ªåŒ…")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æ›´å¤šæ•°æ®
                if not self._has_more_pages(data, packages):
                    break
                
                page += 1
                time.sleep(0.5)  # é¿å…è¯·æ±‚è¿‡å¿«
            
            # ä¿å­˜æ•°æ®
            result = {
                'fetcher_type': 'APIFetcher',
                'source_url': self.url,
                'total_count': len(all_packages),
                'packages': all_packages,
                'fetch_time': time.time()
            }
            
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            
            print(f"[APIFetcher] æŠ“å–å®Œæˆï¼Œå…± {len(all_packages)} ä¸ªåŒ…")
            return True
            
        except Exception as e:
            print(f"[APIFetcher] æŠ“å–å¤±è´¥: {e}")
            return False
    
    def _build_page_url(self, page: int) -> str:
        """æ„å»ºåˆ†é¡µURL"""
        import re
        url = self.url
        
        # æ›¿æ¢æˆ–æ·»åŠ pageå‚æ•°
        if 'page=' in url:
            url = re.sub(r'page=\d+', f'page={page}', url)
        elif '?' in url:
            url = f"{url}&page={page}"
        else:
            url = f"{url}?page={page}"
        
        # ç¡®ä¿æœ‰pageSizeå‚æ•°
        if 'pageSize=' not in url and 'page_size=' not in url:
            url = f"{url}&pageSize=100"
        
        return url
    
    def _extract_packages(self, data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ä»å“åº”ä¸­æå–åŒ…åˆ—è¡¨"""
        # å°è¯•å¤šç§å¯èƒ½çš„å“åº”æ ¼å¼
        if 'data' in data:
            if isinstance(data['data'], list):
                return data['data']
            elif 'packages' in data['data']:
                return data['data']['packages']
            elif 'items' in data['data']:
                return data['data']['items']
        
        if 'packages' in data:
            return data['packages']
        
        if 'items' in data:
            return data['items']
        
        if isinstance(data, list):
            return data
        
        return []
    
    def _has_more_pages(self, data: Dict[str, Any], packages: List) -> bool:
        """åˆ¤æ–­æ˜¯å¦è¿˜æœ‰æ›´å¤šé¡µ"""
        # å¦‚æœå½“å‰é¡µæ²¡æœ‰æ•°æ®ï¼Œåˆ™æ²¡æœ‰æ›´å¤šé¡µ
        if not packages:
            return False
        
        # æ£€æŸ¥totalå­—æ®µ
        if 'total' in data:
            total = data['total']
            if 'data' in data and 'page' in data['data']:
                page = data['data']['page']
                page_size = data['data'].get('pageSize', 100)
                return page * page_size < total
        
        # å¦‚æœæœ‰paginationä¿¡æ¯
        if 'pagination' in data:
            pagination = data['pagination']
            if 'hasMore' in pagination:
                return pagination['hasMore']
            if 'page' in pagination and 'totalPages' in pagination:
                return pagination['page'] < pagination['totalPages']
        
        # é»˜è®¤ï¼šå¦‚æœåŒ…æ•°é‡ç­‰äºé¡µé¢å¤§å°ï¼Œå¯èƒ½è¿˜æœ‰æ›´å¤š
        return len(packages) >= 100


class APIBatchFetcher(BaseFetcher):
    """
    æ‰¹é‡APIæŠ“å–å™¨ - ç”¨äºæŠ“å– GitCode API æ•°æ®
    å¯¹åº” yaml ä¸­çš„ gitcode_tpc source
    URLæ ¼å¼: https://gitcode.com/api/v5/orgs/openharmony-tpc/repos?per_page=100&page={page}
    æ”¯æŒ {page} å ä½ç¬¦
    """
    
    def fetch(self, output_path: str) -> bool:
        """æŠ“å–GitCode APIæ•°æ®ï¼ˆæ‰¹é‡åˆ†é¡µï¼‰"""
        try:
            print(f"[APIBatchFetcher] æ­£åœ¨æŠ“å–API: {self.url}")
            
            all_repos = []
            page = 1
            max_pages = 50  # æœ€å¤§é¡µæ•°é™åˆ¶
            
            while page <= max_pages:
                # æ›¿æ¢URLä¸­çš„{page}å ä½ç¬¦
                page_url = self.url.replace('{page}', str(page))
                print(f"[APIBatchFetcher] æ­£åœ¨è·å–ç¬¬ {page} é¡µ...")
                
                response = self.session.get(page_url, timeout=self.fetch_timeout)
                response.raise_for_status()
                
                data = response.json()

                # å…¼å®¹å¤šç§é¡¶å±‚ç»“æ„
                if isinstance(data, list):
                    repos = data
                elif isinstance(data, dict):
                    # å¯èƒ½å‡ºç°åœ¨ data / items / repos ç­‰å­—æ®µ
                    repos = data.get('data') or data.get('items') or data.get('repos') or []
                    if isinstance(repos, dict):
                        # æŸäº› API è¿”å› { data: { list: [...] } }
                        repos = repos.get('list') or repos.get('items') or []
                else:
                    repos = []

                if not isinstance(repos, list):
                    print(f"[APIBatchFetcher] æ— æ³•è¯†åˆ«çš„è¿”å›ç»“æ„ï¼Œè·³è¿‡æœ¬é¡µã€‚")
                    repos = []

                if not repos:
                    print(f"[APIBatchFetcher] ç¬¬ {page} é¡µæ— æ•°æ®ï¼Œåœæ­¢æŠ“å–")
                    break
                
                all_repos.extend(repos)
                print(f"[APIBatchFetcher] ç¬¬ {page} é¡µè·å–åˆ° {len(repos)} ä¸ªä»“åº“")
                
                # å¦‚æœè¿”å›çš„ä»“åº“æ•°å°‘äºæ¯é¡µæ•°é‡ï¼Œè¯´æ˜æ˜¯æœ€åä¸€é¡µ
                per_page = self._extract_per_page_from_url()
                if len(repos) < per_page:
                    break
                
                page += 1
                time.sleep(0.5)  # é¿å…è¯·æ±‚è¿‡å¿«
            
            # ä¿å­˜æ•°æ®
            result = {
                'fetcher_type': 'APIBatchFetcher',
                'source_url': self.url,
                'total_count': len(all_repos),
                'repos': all_repos,
                'fetch_time': time.time()
            }
            
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            
            print(f"[APIBatchFetcher] æŠ“å–å®Œæˆï¼Œå…± {len(all_repos)} ä¸ªä»“åº“")
            return True
            
        except Exception as e:
            print(f"[APIBatchFetcher] æŠ“å–å¤±è´¥: {e}")
            return False
    
    def _extract_per_page_from_url(self) -> int:
        """ä»URLä¸­æå–æ¯é¡µæ•°é‡"""
        import re
        match = re.search(r'per_page=(\d+)', self.url)
        if match:
            return int(match.group(1))
        return 100  # é»˜è®¤å€¼


# JsonFetcher æ˜¯ WebpageFetcher çš„åˆ«åï¼Œç”¨äºè¯­ä¹‰ä¸Šæ›´æ¸…æ™°åœ°è¡¨ç¤ºè·å–JSONæ•°æ®
class JsonFetcher(WebpageFetcher):
    """
    JSONæ–‡ä»¶æŠ“å–å™¨ - ç”¨äºæŠ“å–JSONæ ¼å¼çš„æ•°æ®æ–‡ä»¶
    å¯¹åº” yaml ä¸­çš„ JsonFetcher
    å®é™…ä¸Šæ˜¯ WebpageFetcher çš„åˆ«å
    """
    pass


class SeleniumFetcher:
    """
    Seleniumç½‘é¡µæŠ“å–å™¨ - ç”¨äºæŠ“å–JavaScriptæ¸²æŸ“çš„ç½‘é¡µï¼ˆSPAåº”ç”¨ï¼‰
    é€‚ç”¨äº GitCode ç­‰å•é¡µåº”ç”¨
    
    éœ€è¦å®‰è£…: pip install selenium webdriver-manager
    """
    
    def __init__(self, url: str, wait_seconds: int = 10, headless: bool = True, fetch_timeout: int = 60):
        """
        Args:
            url: è¦è®¿é—®çš„URL
            wait_seconds: ç­‰å¾…é¡µé¢åŠ è½½çš„ç§’æ•°
            headless: æ˜¯å¦ä½¿ç”¨æ— å¤´æ¨¡å¼ï¼ˆä¸æ˜¾ç¤ºæµè§ˆå™¨çª—å£ï¼‰
            fetch_timeout: è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆå…¼å®¹å‚æ•°ï¼ŒSeleniumä¸ä½¿ç”¨ï¼‰
        """
        self.url = url
        self.wait_seconds = wait_seconds
        self.headless = headless
        self.fetch_timeout = fetch_timeout
    
    def fetch(self, output_path: str) -> bool:
        """
        ä½¿ç”¨ Selenium è·å–å®Œæ•´æ¸²æŸ“åçš„ HTML
        
        Args:
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            
        Returns:
            bool: æˆåŠŸè¿”å›Trueï¼Œå¤±è´¥è¿”å›False
        """
        try:
            from selenium import webdriver
            from selenium.webdriver.chrome.service import Service
            from selenium.webdriver.chrome.options import Options
            from webdriver_manager.chrome import ChromeDriverManager
        except ImportError as e:
            print(f"[SeleniumFetcher] âŒ ç¼ºå°‘ä¾èµ–åº“: {e}")
            print("[SeleniumFetcher] è¯·è¿è¡Œ: pip install selenium webdriver-manager")
            return False
        
        driver = None
        try:
            # é…ç½®æµè§ˆå™¨é€‰é¡¹
            options = Options()
            if self.headless:
                options.add_argument('--headless')
            options.add_argument('--no-sandbox')
            options.add_argument('--disable-dev-shm-usage')
            options.add_argument('--disable-gpu')
            options.add_argument('--disable-blink-features=AutomationControlled')
            options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
            
            # åˆ›å»ºæµè§ˆå™¨å®ä¾‹
            print(f"[SeleniumFetcher] ğŸŒ æ­£åœ¨å¯åŠ¨ Chrome æµè§ˆå™¨...")
            service = Service(ChromeDriverManager().install())
            driver = webdriver.Chrome(service=service, options=options)
            
            # è®¿é—®é¡µé¢
            print(f"[SeleniumFetcher] ğŸ”— æ­£åœ¨è®¿é—®: {self.url}")
            driver.get(self.url)
            
            # ç­‰å¾…é¡µé¢åŠ è½½
            print(f"[SeleniumFetcher] â³ ç­‰å¾… {self.wait_seconds} ç§’è®©é¡µé¢å®Œå…¨åŠ è½½...")
            time.sleep(self.wait_seconds)
            
            # æ»šåŠ¨é¡µé¢ä»¥è§¦å‘æ‡’åŠ è½½
            print("[SeleniumFetcher] ğŸ“œ æ»šåŠ¨é¡µé¢åŠ è½½æ›´å¤šå†…å®¹...")
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(2)
            
            # è·å–æ¸²æŸ“åçš„HTML
            html = driver.page_source
            
            # ä¿å­˜HTMLå†…å®¹
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(html)
            
            file_size = os.path.getsize(output_path)
            print(f"[SeleniumFetcher] âœ… é¡µé¢æŠ“å–æˆåŠŸï¼Œå¤§å°: {file_size:,} å­—èŠ‚")
            
            # å¯é€‰ï¼šä¿å­˜æˆªå›¾ç”¨äºè°ƒè¯•
            try:
                screenshot_path = output_path.replace('.html', '_screenshot.png')
                driver.save_screenshot(screenshot_path)
                print(f"[SeleniumFetcher] ğŸ“¸ å·²ä¿å­˜é¡µé¢æˆªå›¾åˆ°: {screenshot_path}")
            except:
                pass
            
            return True
            
        except Exception as e:
            print(f"[SeleniumFetcher] âŒ æŠ“å–å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
            
        finally:
            if driver:
                driver.quit()
                print("[SeleniumFetcher] ğŸ”š æµè§ˆå™¨å·²å…³é—­")


def main():
    """æœ€å°äº§ç‰©æ¨¡å¼ï¼šä¸ç›´æ¥äº§å‡ºæ–‡ä»¶ã€‚è¯·é€šè¿‡ start.py è°ƒç”¨ OpenHarmony åˆ†æã€‚"""
    print("OpenHarmony fetchers ready. Use start.py to run minimal artifact generation.")


if __name__ == "__main__":
    main()
